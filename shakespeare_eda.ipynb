{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shakespeare Genre Analysis: TF-IDF, Pearson Correlation, Syntactic Complexity\n",
    "**IDS 570: Text as Data - Data Exploration Assignment**\n",
    "\n",
    "---\n",
    "\n",
    "## Research Question\n",
    "Do Shakespeare's genre categories (tragedy, comedy, history) reflect measurable linguistic patterns?\n",
    "\n",
    "## Corpus\n",
    "~20 Shakespeare plays:\n",
    "- 7-8 Tragedies\n",
    "- 7-8 Comedies  \n",
    "- 4-5 Histories\n",
    "\n",
    "## Methods\n",
    "1. **TF-IDF** (lexical distinctiveness)\n",
    "2. **Pearson Correlation** (text similarity)\n",
    "3. **Syntactic Complexity** (structural analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# NLP libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Syntactic parsing\n",
    "import spacy\n",
    "\n",
    "# Settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "\n",
    "print(\"✓ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 0: Load and Normalize Data\n",
    "\n",
    "### Define Your Corpus\n",
    "**IMPORTANT**: Update the file paths below with YOUR actual play filenames!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your corpus structure\n",
    "# UPDATE THESE WITH YOUR ACTUAL FILENAMES!\n",
    "\n",
    "corpus_info = {\n",
    "    'tragedies': [\n",
    "        'hamlet.txt',\n",
    "        'macbeth.txt',\n",
    "        'othello.txt',\n",
    "        'king_lear.txt',\n",
    "        'romeo_and_juliet.txt',\n",
    "        'julius_caesar.txt',\n",
    "        'antony_and_cleopatra.txt',\n",
    "        # Add more as needed\n",
    "    ],\n",
    "    'comedies': [\n",
    "        'much_ado_about_nothing.txt',\n",
    "        'twelfth_night.txt',\n",
    "        'as_you_like_it.txt',\n",
    "        'midsummer_nights_dream.txt',\n",
    "        'merchant_of_venice.txt',\n",
    "        'taming_of_the_shrew.txt',\n",
    "        'comedy_of_errors.txt',\n",
    "        # Add more as needed\n",
    "    ],\n",
    "    'histories': [\n",
    "        'henry_v.txt',\n",
    "        'richard_iii.txt',\n",
    "        'henry_iv_part1.txt',\n",
    "        'richard_ii.txt',\n",
    "        # Add more as needed\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Path to your plays folder\n",
    "DATA_PATH = Path('shakespeare_plays/')  # UPDATE THIS PATH!\n",
    "\n",
    "print(f\"Corpus structure defined:\")\n",
    "print(f\"  Tragedies: {len(corpus_info['tragedies'])}\")\n",
    "print(f\"  Comedies: {len(corpus_info['comedies'])}\")\n",
    "print(f\"  Histories: {len(corpus_info['histories'])}\")\n",
    "print(f\"  Total: {sum(len(v) for v in corpus_info.values())} plays\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_play(filepath):\n",
    "    \"\"\"Load a single play text file\"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "    except UnicodeDecodeError:\n",
    "        # Try different encoding if utf-8 fails\n",
    "        with open(filepath, 'r', encoding='latin-1') as f:\n",
    "            return f.read()\n",
    "\n",
    "# Load all plays\n",
    "plays = {}\n",
    "play_genres = {}\n",
    "\n",
    "for genre, filenames in corpus_info.items():\n",
    "    for filename in filenames:\n",
    "        filepath = DATA_PATH / filename\n",
    "        play_name = filename.replace('.txt', '').replace('_', ' ').title()\n",
    "        \n",
    "        try:\n",
    "            plays[play_name] = load_play(filepath)\n",
    "            play_genres[play_name] = genre\n",
    "            print(f\"✓ Loaded: {play_name} ({genre})\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"✗ File not found: {filepath}\")\n",
    "\n",
    "print(f\"\\n✓ Successfully loaded {len(plays)} plays\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Normalization\n",
    "\n",
    "**REQUIRED**: Fix long S character  \n",
    "**YOUR CHOICE**: Other normalizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    \"\"\"\n",
    "    Normalize Early Modern English text\n",
    "    \n",
    "    REQUIRED:\n",
    "    - Fix long S (ſ → s)\n",
    "    \n",
    "    OPTIONAL (your choice):\n",
    "    - u/v normalization\n",
    "    - i/j normalization\n",
    "    - Remove punctuation\n",
    "    - Lowercase\n",
    "    \"\"\"\n",
    "    # REQUIRED: Fix long S\n",
    "    text = text.replace('ſ', 's')\n",
    "    \n",
    "    # OPTIONAL: Add other normalizations here if desired\n",
    "    # Uncomment the ones you want to use:\n",
    "    \n",
    "    # text = text.replace('u', 'v')  # u/v normalization\n",
    "    # text = text.replace('i', 'j')  # i/j normalization\n",
    "    # text = text.lower()  # lowercase\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply normalization to all plays\n",
    "plays_normalized = {name: normalize_text(text) for name, text in plays.items()}\n",
    "\n",
    "print(\"✓ Text normalization complete\")\n",
    "print(\"\\nNormalization choices:\")\n",
    "print(\"  - Fixed long S character (ſ → s): YES (required)\")\n",
    "print(\"  - Other normalizations: [UPDATE THIS BASED ON YOUR CHOICES]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataFrame for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with all plays\n",
    "df_plays = pd.DataFrame({\n",
    "    'play': list(plays_normalized.keys()),\n",
    "    'text': list(plays_normalized.values()),\n",
    "    'genre': [play_genres[name] for name in plays_normalized.keys()]\n",
    "})\n",
    "\n",
    "# Add word counts\n",
    "df_plays['word_count'] = df_plays['text'].apply(lambda x: len(x.split()))\n",
    "\n",
    "print(df_plays[['play', 'genre', 'word_count']].to_string())\n",
    "print(f\"\\nGenre distribution:\")\n",
    "print(df_plays['genre'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 1: TF-IDF Analysis\n",
    "\n",
    "### Calculate TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF vectorizer\n",
    "# You can adjust these parameters:\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=5000,        # Keep top 5000 features\n",
    "    min_df=2,                 # Word must appear in at least 2 documents\n",
    "    max_df=0.8,               # Word can't appear in more than 80% of documents\n",
    "    stop_words='english',     # Remove common English stop words\n",
    "    lowercase=True,\n",
    "    token_pattern=r'\\b[a-zA-Z]{3,}\\b'  # Only words with 3+ letters\n",
    ")\n",
    "\n",
    "# Fit and transform\n",
    "tfidf_matrix = tfidf.fit_transform(df_plays['text'])\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "print(f\"TF-IDF matrix shape: {tfidf_matrix.shape}\")\n",
    "print(f\"({tfidf_matrix.shape[0]} documents × {tfidf_matrix.shape[1]} features)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Top TF-IDF Terms per Play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_tfidf_terms(doc_index, n=15):\n",
    "    \"\"\"Get top N TF-IDF terms for a document\"\"\"\n",
    "    tfidf_scores = tfidf_matrix[doc_index].toarray()[0]\n",
    "    top_indices = tfidf_scores.argsort()[-n:][::-1]\n",
    "    top_terms = [(feature_names[i], tfidf_scores[i]) for i in top_indices]\n",
    "    return top_terms\n",
    "\n",
    "# Get top terms for each play\n",
    "top_terms_per_play = {}\n",
    "for idx, row in df_plays.iterrows():\n",
    "    top_terms_per_play[row['play']] = get_top_tfidf_terms(idx, n=15)\n",
    "\n",
    "# Display results\n",
    "print(\"=\" * 80)\n",
    "print(\"TOP 15 TF-IDF TERMS PER PLAY\")\n",
    "print(\"=\" * 80)\n",
    "for play, terms in top_terms_per_play.items():\n",
    "    genre = df_plays[df_plays['play'] == play]['genre'].values[0]\n",
    "    print(f\"\\n{play} ({genre.upper()})\")\n",
    "    print(\"-\" * 60)\n",
    "    terms_str = \", \".join([f\"{term}({score:.3f})\" for term, score in terms])\n",
    "    print(terms_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create TF-IDF Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a clean table for your report\n",
    "tfidf_summary = []\n",
    "for play, terms in top_terms_per_play.items():\n",
    "    genre = df_plays[df_plays['play'] == play]['genre'].values[0]\n",
    "    top_words = \", \".join([term for term, score in terms[:10]])\n",
    "    tfidf_summary.append({\n",
    "        'Play': play,\n",
    "        'Genre': genre,\n",
    "        'Top 10 Distinctive Terms': top_words\n",
    "    })\n",
    "\n",
    "df_tfidf_summary = pd.DataFrame(tfidf_summary)\n",
    "print(df_tfidf_summary.to_string(index=False))\n",
    "\n",
    "# Save to CSV\n",
    "df_tfidf_summary.to_csv('tfidf_results.csv', index=False)\n",
    "print(\"\\n✓ Saved to tfidf_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Interpretation\n",
    "\n",
    "**Answer at least 2 of these questions:**\n",
    "\n",
    "1. **Do some documents share distinctive vocabulary?**\n",
    "   - [Your answer here]\n",
    "\n",
    "2. **Are distinctive terms topical, rhetorical, or technical?**\n",
    "   - [Your answer here]\n",
    "\n",
    "3. **Are there documents whose distinctiveness seems driven by noise or formatting?**\n",
    "   - [Your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 2: Pearson Correlation Analysis\n",
    "\n",
    "### Calculate Pairwise Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert TF-IDF matrix to dense array\n",
    "tfidf_dense = tfidf_matrix.toarray()\n",
    "\n",
    "# Calculate Pearson correlation matrix\n",
    "correlation_matrix = np.corrcoef(tfidf_dense)\n",
    "\n",
    "# Create DataFrame with play names\n",
    "df_corr = pd.DataFrame(\n",
    "    correlation_matrix,\n",
    "    index=df_plays['play'],\n",
    "    columns=df_plays['play']\n",
    ")\n",
    "\n",
    "# Round for readability\n",
    "df_corr = df_corr.round(3)\n",
    "\n",
    "print(\"Correlation matrix shape:\", df_corr.shape)\n",
    "print(\"\\nFirst 5x5 subset:\")\n",
    "print(df_corr.iloc[:5, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Similarity Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap\n",
    "plt.figure(figsize=(14, 12))\n",
    "\n",
    "# Create heatmap with better color scheme\n",
    "sns.heatmap(\n",
    "    df_corr,\n",
    "    cmap='RdBu_r',           # Red-Blue diverging colormap\n",
    "    center=0,                # Center at 0\n",
    "    vmin=-1, vmax=1,         # Correlation range\n",
    "    square=True,             # Square cells\n",
    "    linewidths=0.5,          # Grid lines\n",
    "    cbar_kws={\"shrink\": 0.8, \"label\": \"Pearson Correlation\"},\n",
    "    annot=False              # Set to True if you want numbers in cells\n",
    ")\n",
    "\n",
    "plt.title('Pearson Correlation Between Shakespeare Plays', fontsize=16, pad=20)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "plt.savefig('pearson_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "print(\"✓ Saved heatmap to pearson_heatmap.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Most and Least Similar Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get upper triangle (to avoid duplicates and diagonal)\n",
    "mask = np.triu(np.ones_like(df_corr), k=1).astype(bool)\n",
    "corr_values = df_corr.where(mask)\n",
    "\n",
    "# Convert to long format\n",
    "corr_long = corr_values.stack().reset_index()\n",
    "corr_long.columns = ['Play_1', 'Play_2', 'Correlation']\n",
    "\n",
    "# Sort by correlation\n",
    "corr_sorted = corr_long.sort_values('Correlation', ascending=False)\n",
    "\n",
    "# Most similar pairs\n",
    "print(\"=\" * 80)\n",
    "print(\"TOP 5 MOST SIMILAR PLAY PAIRS\")\n",
    "print(\"=\" * 80)\n",
    "for idx, row in corr_sorted.head(5).iterrows():\n",
    "    genre1 = df_plays[df_plays['play'] == row['Play_1']]['genre'].values[0]\n",
    "    genre2 = df_plays[df_plays['play'] == row['Play_2']]['genre'].values[0]\n",
    "    print(f\"{row['Play_1']} ({genre1}) <--> {row['Play_2']} ({genre2})\")\n",
    "    print(f\"  Correlation: {row['Correlation']:.3f}\")\n",
    "    print()\n",
    "\n",
    "# Least similar pairs\n",
    "print(\"=\" * 80)\n",
    "print(\"TOP 5 LEAST SIMILAR PLAY PAIRS\")\n",
    "print(\"=\" * 80)\n",
    "for idx, row in corr_sorted.tail(5).iterrows():\n",
    "    genre1 = df_plays[df_plays['play'] == row['Play_1']]['genre'].values[0]\n",
    "    genre2 = df_plays[df_plays['play'] == row['Play_2']]['genre'].values[0]\n",
    "    print(f\"{row['Play_1']} ({genre1}) <--> {row['Play_2']} ({genre2})\")\n",
    "    print(f\"  Correlation: {row['Correlation']:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson Correlation Interpretation\n",
    "\n",
    "**Required answers:**\n",
    "\n",
    "1. **Two most similar document pairs:**\n",
    "   - [Your answer here]\n",
    "\n",
    "2. **Two least similar document pairs:**\n",
    "   - [Your answer here]\n",
    "\n",
    "3. **What questions would you ask from this corpus after seeing these patterns?**\n",
    "   - [Your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 3: Syntactic Complexity Analysis\n",
    "\n",
    "### Select Two Plays for Comparison\n",
    "\n",
    "**Based on your TF-IDF and Pearson results, choose 2 plays to compare**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATE THESE WITH YOUR CHOSEN PLAYS!\n",
    "play1_name = \"Hamlet\"  # Replace with actual play name\n",
    "play2_name = \"Twelfth Night\"  # Replace with actual play name\n",
    "\n",
    "# Get texts\n",
    "play1_text = df_plays[df_plays['play'] == play1_name]['text'].values[0]\n",
    "play2_text = df_plays[df_plays['play'] == play2_name]['text'].values[0]\n",
    "\n",
    "print(f\"Selected plays for syntactic analysis:\")\n",
    "print(f\"  Play 1: {play1_name}\")\n",
    "print(f\"  Play 2: {play2_name}\")\n",
    "print(f\"\\nReason for selection: [WRITE YOUR REASONING HERE]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Spacy Model for Syntactic Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spaCy English model\n",
    "# If not installed, run: python -m spacy download en_core_web_sm\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    print(\"✓ Spacy model loaded successfully\")\n",
    "except:\n",
    "    print(\"Please install spacy model:\")\n",
    "    print(\"  python -m spacy download en_core_web_sm\")\n",
    "    raise\n",
    "\n",
    "# For large texts, increase max_length\n",
    "nlp.max_length = 2000000  # Increase as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Syntactic Complexity Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_syntactic_complexity(text, play_name):\n",
    "    \"\"\"\n",
    "    Calculate syntactic complexity measures for a text\n",
    "    \n",
    "    Returns:\n",
    "    - Mean Length of Sentence (MLS)\n",
    "    - Clauses per Sentence (C/S)\n",
    "    - Dependent Clauses per Sentence\n",
    "    - Coordination per Sentence\n",
    "    - Complex Nominals per Sentence\n",
    "    \"\"\"\n",
    "    print(f\"Parsing {play_name}... (this may take a few minutes)\")\n",
    "    \n",
    "    # Parse text\n",
    "    doc = nlp(text[:500000])  # Limit to first 500k chars if needed\n",
    "    \n",
    "    # Initialize counters\n",
    "    sentences = list(doc.sents)\n",
    "    n_sentences = len(sentences)\n",
    "    \n",
    "    total_words = 0\n",
    "    total_clauses = 0\n",
    "    total_dependent_clauses = 0\n",
    "    total_coordination = 0\n",
    "    total_complex_nominals = 0\n",
    "    \n",
    "    for sent in sentences:\n",
    "        # Word count\n",
    "        words = [token for token in sent if not token.is_punct]\n",
    "        total_words += len(words)\n",
    "        \n",
    "        # Clause count (simplified: count verbs)\n",
    "        verbs = [token for token in sent if token.pos_ == \"VERB\"]\n",
    "        total_clauses += len(verbs)\n",
    "        \n",
    "        # Dependent clauses (advcl, acl, ccomp, xcomp)\n",
    "        dep_clauses = [token for token in sent if token.dep_ in ['advcl', 'acl', 'ccomp', 'xcomp']]\n",
    "        total_dependent_clauses += len(dep_clauses)\n",
    "        \n",
    "        # Coordination (conj)\n",
    "        coord = [token for token in sent if token.dep_ == 'conj']\n",
    "        total_coordination += len(coord)\n",
    "        \n",
    "        # Complex nominals (noun with modifiers)\n",
    "        nouns_with_mods = [token for token in sent if token.pos_ == 'NOUN' and \n",
    "                          any(child.dep_ in ['amod', 'nmod', 'acl', 'relcl'] for child in token.children)]\n",
    "        total_complex_nominals += len(nouns_with_mods)\n",
    "    \n",
    "    # Calculate measures\n",
    "    results = {\n",
    "        'play': play_name,\n",
    "        'sentences': n_sentences,\n",
    "        'MLS': total_words / n_sentences if n_sentences > 0 else 0,\n",
    "        'C/S': total_clauses / n_sentences if n_sentences > 0 else 0,\n",
    "        'DC/S': total_dependent_clauses / n_sentences if n_sentences > 0 else 0,\n",
    "        'Coord/S': total_coordination / n_sentences if n_sentences > 0 else 0,\n",
    "        'CN/S': total_complex_nominals / n_sentences if n_sentences > 0 else 0\n",
    "    }\n",
    "    \n",
    "    print(f\"✓ Parsing complete for {play_name}\")\n",
    "    return results, doc\n",
    "\n",
    "print(\"✓ Syntactic complexity functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Complexity for Both Plays\n",
    "\n",
    "**WARNING**: This may take 5-10 minutes per play!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate for Play 1\n",
    "results1, doc1 = calculate_syntactic_complexity(play1_text, play1_name)\n",
    "\n",
    "# Calculate for Play 2\n",
    "results2, doc2 = calculate_syntactic_complexity(play2_text, play2_name)\n",
    "\n",
    "print(\"\\n✓ Syntactic analysis complete for both plays!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "df_syntax = pd.DataFrame([results1, results2])\n",
    "df_syntax = df_syntax.set_index('play')\n",
    "\n",
    "# Format for display\n",
    "df_syntax_display = df_syntax.copy()\n",
    "for col in ['MLS', 'C/S', 'DC/S', 'Coord/S', 'CN/S']:\n",
    "    df_syntax_display[col] = df_syntax_display[col].round(2)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SYNTACTIC COMPLEXITY COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "print(df_syntax_display.to_string())\n",
    "print(\"\\nMeasures:\")\n",
    "print(\"  MLS = Mean Length of Sentence\")\n",
    "print(\"  C/S = Clauses per Sentence\")\n",
    "print(\"  DC/S = Dependent Clauses per Sentence\")\n",
    "print(\"  Coord/S = Coordination per Sentence\")\n",
    "print(\"  CN/S = Complex Nominals per Sentence\")\n",
    "\n",
    "# Save to CSV\n",
    "df_syntax_display.to_csv('syntactic_complexity.csv')\n",
    "print(\"\\n✓ Saved to syntactic_complexity.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Syntactic Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bar chart comparison\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "measures = ['MLS', 'C/S', 'DC/S', 'Coord/S', 'CN/S']\n",
    "x = np.arange(len(measures))\n",
    "width = 0.35\n",
    "\n",
    "play1_values = [results1[m] for m in measures]\n",
    "play2_values = [results2[m] for m in measures]\n",
    "\n",
    "ax.bar(x - width/2, play1_values, width, label=play1_name, alpha=0.8)\n",
    "ax.bar(x + width/2, play2_values, width, label=play2_name, alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Measure', fontsize=12)\n",
    "ax.set_ylabel('Value', fontsize=12)\n",
    "ax.set_title('Syntactic Complexity Comparison', fontsize=14)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(measures)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('syntactic_comparison.png', dpi=300, bbox_inches='tight')\n",
    "print(\"✓ Saved chart to syntactic_comparison.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Example Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_example_sentence(doc, play_name, criterion='longest'):\n",
    "    \"\"\"\n",
    "    Find an example sentence based on criterion\n",
    "    \n",
    "    criterion: 'longest', 'most_complex', 'most_coordination'\n",
    "    \"\"\"\n",
    "    sentences = list(doc.sents)\n",
    "    \n",
    "    if criterion == 'longest':\n",
    "        # Find longest sentence\n",
    "        sent = max(sentences, key=lambda s: len([t for t in s if not t.is_punct]))\n",
    "    elif criterion == 'most_complex':\n",
    "        # Find sentence with most dependent clauses\n",
    "        sent = max(sentences, key=lambda s: len([t for t in s if t.dep_ in ['advcl', 'acl', 'ccomp', 'xcomp']]))\n",
    "    elif criterion == 'most_coordination':\n",
    "        # Find sentence with most coordination\n",
    "        sent = max(sentences, key=lambda s: len([t for t in s if t.dep_ == 'conj']))\n",
    "    \n",
    "    return sent.text.strip()\n",
    "\n",
    "# Get example sentences\n",
    "print(\"=\" * 80)\n",
    "print(\"EXAMPLE SENTENCES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\n{play1_name} - Longest Sentence:\")\n",
    "print(\"-\" * 60)\n",
    "example1 = find_example_sentence(doc1, play1_name, 'longest')\n",
    "print(example1[:500] + \"...\" if len(example1) > 500 else example1)\n",
    "\n",
    "print(f\"\\n{play2_name} - Longest Sentence:\")\n",
    "print(\"-\" * 60)\n",
    "example2 = find_example_sentence(doc2, play2_name, 'longest')\n",
    "print(example2[:500] + \"...\" if len(example2) > 500 else example2)\n",
    "\n",
    "print(f\"\\n{play1_name} - Most Complex (dependent clauses):\")\n",
    "print(\"-\" * 60)\n",
    "example3 = find_example_sentence(doc1, play1_name, 'most_complex')\n",
    "print(example3[:500] + \"...\" if len(example3) > 500 else example3)\n",
    "\n",
    "print(f\"\\n{play2_name} - Most Complex (dependent clauses):\")\n",
    "print(\"-\" * 60)\n",
    "example4 = find_example_sentence(doc2, play2_name, 'most_complex')\n",
    "print(example4[:500] + \"...\" if len(example4) > 500 else example4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syntactic Complexity Interpretation\n",
    "\n",
    "**Required answers:**\n",
    "\n",
    "1. **How do the two texts differ in syntactic complexity?**\n",
    "   - [Your answer here]\n",
    "\n",
    "2. **Do these differences align with or complicate your earlier lexical findings?**\n",
    "   - [Your answer here]\n",
    "\n",
    "3. **What kinds of rhetorical or stylistic practices might these syntactic patterns reflect?**\n",
    "   - [Your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 4: SYNTHESIS\n",
    "\n",
    "### Triangulating Evidence Across All Three Approaches\n",
    "\n",
    "**This is the most important section!**\n",
    "\n",
    "Articulate one central analytical question/hypothesis that draws on:\n",
    "- TF-IDF evidence\n",
    "- Pearson similarity/distance evidence  \n",
    "- Syntactic complexity evidence\n",
    "\n",
    "---\n",
    "\n",
    "### Central Question/Hypothesis:\n",
    "\n",
    "[WRITE YOUR CENTRAL QUESTION HERE]\n",
    "\n",
    "Example: \"Do Shakespeare's genre categories (tragedy, comedy, history) reflect measurable linguistic patterns, or are they primarily thematic/plot-based distinctions?\"\n",
    "\n",
    "---\n",
    "\n",
    "### Evidence from TF-IDF:\n",
    "\n",
    "[SUMMARIZE KEY FINDINGS FROM TF-IDF]\n",
    "\n",
    "Example:\n",
    "- Tragedies share vocabulary related to death, blood, revenge, fate\n",
    "- Comedies share vocabulary related to love, marriage, jest, disguise\n",
    "- Character names dominate distinctive terms\n",
    "\n",
    "---\n",
    "\n",
    "### Evidence from Pearson Correlation:\n",
    "\n",
    "[SUMMARIZE KEY FINDINGS FROM CORRELATION ANALYSIS]\n",
    "\n",
    "Example:\n",
    "- Strong within-genre clustering (tragedies correlate with tragedies)\n",
    "- Clear separation between tragedy and comedy\n",
    "- BUT some plays bridge categories (e.g., Merchant of Venice)\n",
    "- Histories form distinct cluster\n",
    "\n",
    "---\n",
    "\n",
    "### Evidence from Syntactic Complexity:\n",
    "\n",
    "[SUMMARIZE KEY FINDINGS FROM SYNTAX ANALYSIS]\n",
    "\n",
    "Example:\n",
    "- Hamlet shows higher complexity: longer sentences, more subordination\n",
    "- Twelfth Night shows simpler structures: coordination, shorter sentences\n",
    "- Syntactic differences align with lexical differences\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "[YOUR SYNTHESIS AND CONCLUSIONS]\n",
    "\n",
    "Example:\n",
    "\"Shakespeare's genres are computationally distinguishable across multiple dimensions. Tragedies and comedies differ not only in vocabulary (what they discuss) but in syntax (how they construct arguments). However, problem plays and late romances resist clean classification, suggesting genre exists on a spectrum rather than as rigid categories. This analysis demonstrates that computational methods can illuminate both the coherence of traditional genre labels and their limitations.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary of Outputs\n",
    "\n",
    "### Files Generated:\n",
    "1. `tfidf_results.csv` - Top TF-IDF terms per play\n",
    "2. `pearson_heatmap.png` - Correlation heatmap\n",
    "3. `syntactic_complexity.csv` - Complexity measures\n",
    "4. `syntactic_comparison.png` - Bar chart comparison\n",
    "\n",
    "### For Your Report:\n",
    "- Include all visualizations\n",
    "- Reference tables in your analysis\n",
    "- Answer all interpretive questions\n",
    "- Write synthesis section\n",
    "\n",
    "### For Canvas Submission:\n",
    "- Post this notebook to GitHub\n",
    "- Include link in Discussion Board post\n",
    "- Upload all PNG files\n",
    "- Write your report with interpretations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Notes & Reflections\n",
    "\n",
    "[Use this space for any additional notes, observations, or ideas that emerged during your analysis]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
